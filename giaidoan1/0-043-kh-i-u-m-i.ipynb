{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59156,"databundleVersionId":13874099,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport lightgbm as lgb\nfrom tqdm.auto import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nimport itertools\n\n# --- 1. C·∫§U H√åNH ---\nDATA_PATH = '/kaggle/input/MABe-mouse-behavior-detection/'\nNUM_VIDEOS_TRAIN = 50 \nMIN_DURATION_FRAMES = 3  # L·ªçc b·ªè c√°c h√†nh ƒë·ªông ng·∫Øn h∆°n 3 frame (kho·∫£ng 0.1s)\n\n# --- 2. H√ÄM FEATURE ENGINEERING N√ÇNG CAO (PHYSICS + SOCIAL) ---\ndef calculate_features_safe(df):\n    # Kh·ªüi t·∫°o m·∫∑c ƒë·ªãnh\n    df['distance'] = 0.0\n    df['velocity_m1'] = 0.0\n    df['velocity_m2'] = 0.0\n    \n    # 1. T√≠nh Kho·∫£ng c√°ch c∆° b·∫£n\n    if 'mouse1_body_center_x' in df.columns and 'mouse2_body_center_x' in df.columns:\n        dx = df['mouse1_body_center_x'] - df['mouse2_body_center_x']\n        dy = df['mouse1_body_center_y'] - df['mouse2_body_center_y']\n        df['distance'] = np.sqrt(dx**2 + dy**2)\n    \n    # 2. T√≠nh V·∫≠n t·ªëc M1\n    if 'mouse1_body_center_x' in df.columns:\n        vx1 = df['mouse1_body_center_x'].diff().fillna(0)\n        vy1 = df['mouse1_body_center_y'].diff().fillna(0)\n        df['velocity_m1'] = np.sqrt(vx1**2 + vy1**2)\n        \n    # 3. T√≠nh V·∫≠n t·ªëc M2\n    if 'mouse2_body_center_x' in df.columns:\n        vx2 = df['mouse2_body_center_x'].diff().fillna(0)\n        vy2 = df['mouse2_body_center_y'].diff().fillna(0)\n        df['velocity_m2'] = np.sqrt(vx2**2 + vy2**2)\n        \n    # 4. T√≠nh Gia t·ªëc (Acceleration) - NEW\n    df['accel_m1'] = df['velocity_m1'].diff().fillna(0)\n    df['accel_m2'] = df['velocity_m2'].diff().fillna(0)\n\n    # 5. Social Feature: Kho·∫£ng c√°ch M≈©i - ƒêu√¥i (Quan tr·ªçng cho Chase/Sniff Genital) - NEW\n    if 'mouse1_nose_x' in df.columns and 'mouse2_tail_base_x' in df.columns:\n        df['nose1_to_tail2'] = np.sqrt(\n            (df['mouse1_nose_x'] - df['mouse2_tail_base_x'])**2 + \n            (df['mouse1_nose_y'] - df['mouse2_tail_base_y'])**2\n        )\n    else:\n        df['nose1_to_tail2'] = 0.0\n\n    # 6. Social Feature: Kho·∫£ng c√°ch M≈©i - M≈©i (Quan tr·ªçng cho Sniff Face) - NEW\n    if 'mouse1_nose_x' in df.columns and 'mouse2_nose_x' in df.columns:\n        df['nose1_to_nose2'] = np.sqrt(\n            (df['mouse1_nose_x'] - df['mouse2_nose_x'])**2 + \n            (df['mouse1_nose_y'] - df['mouse2_nose_y'])**2\n        )\n    else:\n        df['nose1_to_nose2'] = 0.0\n\n    # 7. Social Feature: Facing Angle (Chu·ªôt 1 c√≥ nh√¨n v√†o Chu·ªôt 2 kh√¥ng?) - NEW\n    if 'mouse1_nose_x' in df.columns and 'mouse1_body_center_x' in df.columns and 'mouse2_body_center_x' in df.columns:\n        # Vector c∆° th·ªÉ chu·ªôt 1\n        vec1_x = df['mouse1_nose_x'] - df['mouse1_body_center_x']\n        vec1_y = df['mouse1_nose_y'] - df['mouse1_body_center_y']\n        # Vector t·ª´ Chu·ªôt 1 -> Chu·ªôt 2\n        vec12_x = df['mouse2_body_center_x'] - df['mouse1_body_center_x']\n        vec12_y = df['mouse2_body_center_y'] - df['mouse1_body_center_y']\n        \n        dot_product = vec1_x * vec12_x + vec1_y * vec12_y\n        norm1 = np.sqrt(vec1_x**2 + vec1_y**2)\n        norm12 = np.sqrt(vec12_x**2 + vec12_y**2)\n        df['facing_angle_m1'] = dot_product / (norm1 * norm12 + 1e-6)\n    else:\n        df['facing_angle_m1'] = 0.0\n\n    # 8. Rolling Stats (Memory)\n    w = 10\n    cols_to_roll = ['distance', 'velocity_m1', 'velocity_m2', 'accel_m1', 'nose1_to_tail2', 'facing_angle_m1']\n    for col in cols_to_roll:\n        df[f'{col}_mean_{w}'] = df[col].rolling(window=w).mean().fillna(0)\n    \n    return df.fillna(0)\n\n# C·∫≠p nh·∫≠t danh s√°ch features\nfeatures = [\n    'distance', 'velocity_m1', 'velocity_m2', \n    'accel_m1', 'accel_m2', \n    'nose1_to_tail2', 'nose1_to_nose2', 'facing_angle_m1',\n    'distance_mean_10', 'velocity_m1_mean_10', 'velocity_m2_mean_10', \n    'accel_m1_mean_10', 'nose1_to_tail2_mean_10', 'facing_angle_m1_mean_10'\n]\n\n# --- 3. H√ÄM LOAD DATA (GI·ªÆ NGUY√äN LOGIC, CH·ªà G·ªåI FEATURE M·ªöI) ---\ndef load_train_data_all_pairs(meta_row):\n    try:\n        video_id = meta_row['video_id']\n        lab_id = meta_row['lab_id']\n        pix_per_cm = meta_row['pix_per_cm_approx'] if meta_row['pix_per_cm_approx'] > 0 else 1.0\n        \n        t_path = os.path.join(DATA_PATH, 'train_tracking', lab_id, f'{video_id}.parquet')\n        a_path = os.path.join(DATA_PATH, 'train_annotation', lab_id, f'{video_id}.parquet')\n        \n        if not os.path.exists(t_path) or not os.path.exists(a_path): return None\n        \n        df_track = pd.read_parquet(t_path)\n        px = df_track.pivot(index='video_frame', columns=['mouse_id', 'bodypart'], values='x')\n        px.columns = [f\"mouse{m}_{bp}_x\" for m, bp in px.columns]\n        py = df_track.pivot(index='video_frame', columns=['mouse_id', 'bodypart'], values='y')\n        py.columns = [f\"mouse{m}_{bp}_y\" for m, bp in py.columns]\n        df_wide = pd.concat([px, py], axis=1).sort_index(axis=1)\n        \n        df_wide = df_wide.interpolate(limit=5).fillna(0)\n        df_wide = df_wide / pix_per_cm \n        \n        df_annot = pd.read_parquet(a_path)\n        \n        mouse_ids = sorted(list(set([int(c.split('_')[0].replace('mouse', '')) for c in df_wide.columns if 'mouse' in c])))\n        pairs_data = []\n        \n        for m1, m2 in itertools.combinations(mouse_ids, 2):\n            cols1 = [c for c in df_wide.columns if f'mouse{m1}_' in c]\n            cols2 = [c for c in df_wide.columns if f'mouse{m2}_' in c]\n            if not cols1 or not cols2: continue\n\n            df_pair = df_wide[cols1 + cols2].copy()\n            rename_dict = {}\n            for c in cols1: rename_dict[c] = c.replace(f'mouse{m1}_', 'mouse1_')\n            for c in cols2: rename_dict[c] = c.replace(f'mouse{m2}_', 'mouse2_')\n            df_pair.rename(columns=rename_dict, inplace=True)\n            \n            df_pair['label'] = 'other'\n            mask = ((df_annot['agent_id'] == m1) & (df_annot['target_id'] == m2)) | \\\n                   ((df_annot['agent_id'] == m2) & (df_annot['target_id'] == m1))\n            \n            pair_annot = df_annot[mask]\n            for _, r in pair_annot.iterrows():\n                if r['stop_frame'] <= df_pair.index.max():\n                    df_pair.loc[r['start_frame']:r['stop_frame'], 'label'] = r['action']\n                    \n            pairs_data.append(df_pair)\n            \n        if pairs_data:\n            return pd.concat(pairs_data, ignore_index=True)\n    except Exception as e:\n        return None\n    return None\n\n# --- 4. CHU·∫®N B·ªä D·ªÆ LI·ªÜU (B·ªé DOWNSAMPLING 1:1) ---\nprint(\"‚è≥ ƒêang t·∫°o d·ªØ li·ªáu 'All-Pairs' t·ª´ 50 video...\")\ntry:\n    df_meta = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\nexcept:\n    df_meta = pd.DataFrame()\n\nall_train_dfs = []\nfor i in tqdm(range(min(NUM_VIDEOS_TRAIN, len(df_meta)))):\n    df = load_train_data_all_pairs(df_meta.iloc[i])\n    if df is not None:\n        df = calculate_features_safe(df) \n        all_train_dfs.append(df[features + ['label']])\n\nif len(all_train_dfs) > 0:\n    df_train_big = pd.concat(all_train_dfs, ignore_index=True)\n    del all_train_dfs\n    gc.collect()\n\n    print(f\"‚úÖ D·ªØ li·ªáu th√¥: {df_train_big.shape}\")\n    \n    # --- 5. S·ª¨A L·ªñI CLASS IMBALANCE ---\n    # Thay v√¨ v·ª©t b·ªè d·ªØ li·ªáu 'other', ch√∫ng ta d√πng to√†n b·ªô ho·∫∑c downsample nh·∫π (vd: 3:1)\n    # ·ªû ƒë√¢y d√πng to√†n b·ªô ƒë·ªÉ t·ªëi ƒëa h√≥a th√¥ng tin, LightGBM s·∫Ω x·ª≠ l√Ω b·∫±ng Class Weights\n    print(\"‚öñÔ∏è Kh√¥ng downsample th√¥ b·∫°o. S·ª≠ d·ª•ng Class Weights...\")\n    \n    # Label Encoding\n    le = LabelEncoder()\n    y_train = le.fit_transform(df_train_big['label'])\n    X_train = df_train_big[features]\n    \n    # T√≠nh to√°n Class Weights t·ª± ƒë·ªông\n    classes = np.unique(y_train)\n    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n    weight_dict = dict(zip(classes, weights))\n    print(f\"‚öñÔ∏è Tr·ªçng s·ªë l·ªõp (Class Weights): {weight_dict}\")\n    \n    # --- 6. HU·∫§N LUY·ªÜN LIGHTGBM (UPDATE PARAMS) ---\n    print(\"üöÄ ƒêang hu·∫•n luy·ªán LightGBM v·ªõi Class Weights...\")\n    params = {\n        'objective': 'multiclass',\n        'num_class': len(le.classes_),\n        'metric': 'multi_logloss',\n        'boosting_type': 'gbdt',\n        'n_jobs': -1,\n        'random_state': 42,\n        'learning_rate': 0.05,\n        'n_estimators': 1000,        # TƒÉng s·ªë c√¢y v√¨ d·ªØ li·ªáu nhi·ªÅu h∆°n\n        'class_weight': weight_dict, # <--- QUAN TR·ªåNG NH·∫§T: X·ª≠ l√Ω m·∫•t c√¢n b·∫±ng\n        'colsample_bytree': 0.8,     # Subsampling ƒë·ªÉ ch·ªëng overfit\n        'subsample': 0.8,\n        'verbosity': -1,\n        'device': 'gpu',           # <--- TH√äM D√íNG N√ÄY\n    'gpu_platform_id': 0,\n    'gpu_device_id': 0\n    }\n\n    model = lgb.LGBMClassifier(**params)\n    model.fit(X_train, y_train)\n    print(\"üéâ Hu·∫•n luy·ªán xong!\")\n\nelse:\n    print(\"‚ùå Kh√¥ng load ƒë∆∞·ª£c d·ªØ li·ªáu n√†o.\")\n\n# --- 7. H√ÄM POST-PROCESSING (UPDATE: MIN DURATION) ---\ndef run_length_encoding_pro(predictions, agent_id, target_id):\n    events = []\n    if len(predictions) == 0: return events\n    \n    current_label = predictions[0]\n    start_frame = 0\n    \n    for i in range(1, len(predictions)):\n        if predictions[i] != current_label:\n            # Ch·ªâ l∆∞u n·∫øu kh√¥ng ph·∫£i 'other' V√Ä ƒë·ªô d√†i h√†nh ƒë·ªông ƒë·ªß l·ªõn (gi·∫£m nhi·ªÖu)\n            if current_label != 'other' and (i - start_frame) >= MIN_DURATION_FRAMES:\n                events.append({\n                    'agent_id': agent_id,\n                    'target_id': target_id,\n                    'action': current_label,\n                    'start_frame': start_frame,\n                    'stop_frame': i - 1\n                })\n            current_label = predictions[i]\n            start_frame = i\n            \n    # X·ª≠ l√Ω ƒëo·∫°n cu·ªëi c√πng\n    if current_label != 'other' and (len(predictions) - start_frame) >= MIN_DURATION_FRAMES:\n        events.append({\n            'agent_id': agent_id,\n            'target_id': target_id,\n            'action': current_label,\n            'start_frame': start_frame,\n            'stop_frame': len(predictions) - 1\n        })\n    return events\n\n# --- 8. T·∫†O SUBMISSION ---\nif 'model' in locals():\n    print(\"üìù ƒêang t·∫°o submission...\")\n    try:\n        df_test_meta = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n    except: df_test_meta = pd.DataFrame()\n\n    submission_rows = []\n    row_id_counter = 0\n\n    for idx, row in tqdm(df_test_meta.iterrows(), total=len(df_test_meta)):\n        try:\n            video_id = row['video_id']\n            lab_id = row['lab_id']\n            pix_per_cm = row['pix_per_cm_approx'] if row['pix_per_cm_approx'] > 0 else 1.0\n            \n            t_path = os.path.join(DATA_PATH, 'test_tracking', lab_id, f'{video_id}.parquet')\n            if not os.path.exists(t_path): continue\n            \n            df_track = pd.read_parquet(t_path)\n            px = df_track.pivot(index='video_frame', columns=['mouse_id', 'bodypart'], values='x')\n            px.columns = [f\"mouse{m}_{bp}_x\" for m, bp in px.columns]\n            py = df_track.pivot(index='video_frame', columns=['mouse_id', 'bodypart'], values='y')\n            py.columns = [f\"mouse{m}_{bp}_y\" for m, bp in py.columns]\n            df_wide = pd.concat([px, py], axis=1).sort_index(axis=1)\n            \n            df_wide = df_wide.interpolate(limit=5).fillna(0)\n            df_wide = df_wide / pix_per_cm\n            \n            mouse_ids = sorted(list(set([int(c.split('_')[0].replace('mouse', '')) for c in df_wide.columns if 'mouse' in c])))\n            \n            for m1, m2 in itertools.permutations(mouse_ids, 2):\n                cols1 = [c for c in df_wide.columns if f'mouse{m1}_' in c]\n                cols2 = [c for c in df_wide.columns if f'mouse{m2}_' in c]\n                if not cols1 or not cols2: continue\n                \n                df_pair = df_wide[cols1 + cols2].copy()\n                rename_dict = {}\n                for c in cols1: rename_dict[c] = c.replace(f'mouse{m1}_', 'mouse1_')\n                for c in cols2: rename_dict[c] = c.replace(f'mouse{m2}_', 'mouse2_')\n                df_pair.rename(columns=rename_dict, inplace=True)\n                \n                # Feature Engineering\n                df_pair = calculate_features_safe(df_pair)\n                \n                X_test = pd.DataFrame(0.0, index=df_pair.index, columns=features)\n                for c in features:\n                    if c in df_pair.columns: X_test[c] = df_pair[c]\n                \n                # Predict\n                y_pred_idx = model.predict(X_test)\n                y_pred_lbl = le.inverse_transform(y_pred_idx)\n                \n                agent_str = f\"mouse{m1}\"\n                target_str = f\"mouse{m2}\"\n                \n                # Post-processing (Run Length Encoding + Smoothing)\n                events = run_length_encoding_pro(y_pred_lbl, agent_str, target_str)\n                \n                for event in events:\n                    submission_rows.append({\n                        'row_id': row_id_counter,\n                        'video_id': video_id,\n                        'agent_id': event['agent_id'],\n                        'target_id': event['target_id'],\n                        'action': event['action'],\n                        'start_frame': event['start_frame'],\n                        'stop_frame': event['stop_frame']\n                    })\n                    row_id_counter += 1\n                    \n            del df_wide\n            gc.collect()\n        except Exception as e:\n            print(f\"Error processing test video {video_id}: {e}\")\n            continue\n\n    # Save submission\n    sub = pd.DataFrame(submission_rows)\n    if len(sub) == 0:\n        sub = pd.DataFrame(columns=['row_id', 'video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n\n    sub.to_csv('submission.csv', index=False)\n    print(f\"‚úÖ ƒê√£ t·∫°o submission.csv M·ªöI v·ªõi {len(sub)} d√≤ng d·ª± ƒëo√°n.\")\n    display(sub.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}